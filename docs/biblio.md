# Bibliography

Where possible, the bibliography entries use conventions at
<https://www.bibsonomy.org/>
for [*citation keys*](https://bibdesk.sourceforge.io/manual/BibDeskHelp_2.html).

Journal abbreviations come from
<https://academic-accelerator.com/Journal-Abbreviation/System>
based on [*ISO 4*](https://en.wikipedia.org/wiki/ISO_4) standards.

Links to online versions of cited works use
[DOI](https://www.doi.org/)
for [*persistent identifiers*](https://www.crossref.org/education/metadata/persistent-identifiers/).
When available,
[*open access*](https://peerj.com/preprints/3119v1/)
URLs are listed.


## – C –

### cabot2023redfm

["RED<sup>FM</sup>: a Filtered and Multilingual Relation Extraction Dataset"](https://arxiv.org/abs/2306.09802)
**Pere-Lluís Huguet Cabot**, **Simone Tedeschi**, **Axel-Cyrille Ngonga Ngomo**, **Roberto Navigli**
_ACL_ (2023-06-19)
open: <a href="https://arxiv.org/abs/2306.09802" target="_blank">https://arxiv.org/abs/2306.09802</a>
> Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.

## – H –

### hahnr88

["Automatic generation of hypertext knowledge bases"](https://doi.org/10.1145/966861.45429)
**Udo Hahn**, **Ulrich Reimer**
_ACM SIGOIS_ 9:2 (1988-04-01)
open: <a href="https://doi.org/10.1145/966861.45429" target="_blank">https://doi.org/10.1145/966861.45429</a>
> The condensation process transforms the text representation structures resulting from the text parse into a more abstract thematic description of what the text is about, filtering out irrelevant knowledge structures and preserving only the most salient concepts.

### hamilton2020grl

[_Graph Representation Learning_](https://www.cs.mcgill.ca/~wlh/grl_book/)
**William Hamilton**
Morgan and Claypool (pre-print 2020)
open: <a href="https://www.cs.mcgill.ca/~wlh/grl_book/" target="_blank">https://www.cs.mcgill.ca/~wlh/grl_book/</a>
> A brief but comprehensive introduction to graph representation learning, including methods for embedding graph data, graph neural networks, and deep generative models of graphs.

## – L –

### lee2023ingram

["InGram: Inductive Knowledge Graph Embedding via Relation Graphs"](https://arxiv.org/abs/2305.19987)
**Jaejun Lee**, **Chanyoung Chung**, **Joyce Jiyoung Whang**
_ICML_ (2023–08–17)
open: <a href="https://arxiv.org/abs/2305.19987" target="_blank">https://arxiv.org/abs/2305.19987</a>
> In this paper, we propose an INductive knowledge GRAph eMbedding method, InGram, that can generate embeddings of new relations as well as new entities at inference time.

## – M –

### mihalcea04textrank

["TextRank: Bringing Order into Text"](https://www.aclweb.org/anthology/W04-3252/)
**Rada Mihalcea**, **Paul Tarau**
*EMNLP* pp. 404-411 (2004-07-25)
open: <a href="https://aclanthology.org/W04-3252" target="_blank">https://aclanthology.org/W04-3252</a>
> In this paper, the authors introduce TextRank, a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications.
