# TextGraphs: raw texts, LLMs, and KGs, oh my!

<img src="assets/logo.png" width="113" alt="illustration of a lemma graph"/>

Welcome to the **TextGraphs** library...

Large language models (LLMs) -- which are perhaps better described as
_transformers_ -- come from research in natural language.
How can transformers help improve natural language work?
In particular, how can these models be leveraged to benefit use cases
where NLP gets used to build _knowledge graphs_?

If you've been reading the news cycle about AI, one obvious through
rather na√Øve response might be
"Feed your data to ChatGPT and just ask it to generate a knowledge graph."
Those who've tried this approach understand the consequences:
expensive process and poor results, relative to other methods.

That said, are there other ways transformers might help augment
natural language workflows?
This project results from an ongoing pursuit of that line of inquiry.
With sufficiently narrowed task focus and ample software engineering,
transformers can be used to augment specific _components_ of natural
language workflows.
Several important learnings result from this work, and a key take-away
is that the challenges mostly involve software engineering and open
source integration practices.
